{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generative_Text_char_rnn.ipynb","provenance":[{"file_id":"13Vr3PrDg7cc4OZ3W2-grLSVSf0RJYWzb","timestamp":1570075802698}],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h4T2cBVI0s1g","colab_type":"text"},"source":["# A Char-RNN Implementation in Tensorflow\n","---\n","CharRNN was a well known generative text model (character level LSTM) created by Andrej Karpathy. It allowed easy training and generation of arbitrary text with many hilarious results:\n","\n","  * Music: abc notation\n","<https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/>,\n","  * Irish folk music\n","<https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music>-\n","  * Obama speeches\n","<https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0>-\n","  * Eminem lyrics\n","<https://soundcloud.com/mrchrisjohnson/recurrent-neural-shady>- (NSFW ;-))\n","  * Research awards\n","<http://karpathy.github.io/2015/05/21/rnn-effectiveness/#comment-2073825449>-\n","  * TED Talks\n","<https://medium.com/@samim/ted-rnn-machine-generated-ted-talks-3dd682b894c0>-\n","  * Movie Titles <http://www.cs.toronto.edu/~graves/handwriting.html>\n","  \n","This notebook contains a reimplementation in Tensorflow. It will let you input a file containing the text you want your generator to mimic, train your model, see the results, and save it for future use.\n","\n","To get started, start running the cells in order, following the instructions at each step. You will need a sizable text file (try at least 1 MB of text) when prompted to upload one. For exploration you can also use the provided text corpus taken from Shakespeare's works.\n","\n","The training cell saves a checkpoint every 30 seconds, so you can check the output of your network and not lose any progress.\n","\n","## Outline\n","\n","This notebook will guide you through the following steps. Roughly speaking, these will be our steps: \n","  * Upload some data\n","  * Set some training parameters (you can just use the defaults for now)\n","  * Define our Model, training loss function, and data input manager\n","  * Train on a cloud GPU\n","  * Save out model and use it to generate some new text.\n","  \n","Design of the RNN is inspired by [this github project](https://github.com/sherjilozair/char-rnn-tensorflow) which was based on Andrej Karpathy's [char-rnn](https://github.com/karpathy/char-rnn). If you'd like to learn more, Andrej's [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a great place to start."]},{"cell_type":"markdown","metadata":{"id":"NhBCvDKnVstE","colab_type":"text"},"source":["### Imports and Values Needed to Run this Code"]},{"cell_type":"code","metadata":{"id":"67qDGHYCzj6v","colab_type":"code","cellView":"both","colab":{}},"source":["from __future__ import absolute_import, print_function, division\n","from google.colab import files\n","from collections import Counter, defaultdict\n","from copy import deepcopy\n","from IPython.display import clear_output\n","from random import randint\n","\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","CHECKPOINT_DIR = './checkpoints/'  #Checkpoints are temporarily kept here.\n","TEXT_ENCODING = 'utf-8'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mBtu02V2ocXC","colab_type":"text"},"source":["### Get the training data.\n","\n","We can either download the works of Shakespeare to train on or upload our own plain text file that we will be training on."]},{"cell_type":"markdown","metadata":{"id":"GY0UkC_OliHM","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"FvoepQadkPG6","colab_type":"code","outputId":"da0dba4b-6d18-4f68-8e46-77d313715e16","executionInfo":{"status":"ok","timestamp":1570157351356,"user_tz":-180,"elapsed":492,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["#shakespeare_url = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\"\n","#shakespeare_url = \"http://www.gutenberg.org/files/2197/2197-h/2197-h.htm\"\n","shakespeare_url = \"https://raw.githubusercontent.com/stutun1/CharRNN-NLP/master/ozgurluk.txt\"\n","import urllib\n","file_contents = urllib.urlopen(shakespeare_url).read()\n","file_name = \"shakespeare\"\n","file_contents = file_contents[10501:]  # Skip headers and start at content\n","print(\"An excerpt: \\n\", file_contents[:664])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["An excerpt: \n"," ğlayan ve yaş üst sınırı 25 olan Interrail turlarına katılabilmek çok istemiştim. Üniversite sınavı, tıp fakültesi, Tıpta Uzmanlık Sınavı derken gözümü açtığımda yaşım 25’i geçmişti. Duyduğuma göre daha sonra bu yaş sınırını ya kaldırdırlar ya da yükselttiler. Neyse, bakalım. Belki emeklilikte... \n","Bu ihtiyaçlarını yeterli bir seviyede ve yeterli bir süre boyunca tatmin eden kişiler daha sonra yetkinlikleri ile uyumlu sorumluluklar almaya hazır hale gelirler. Temelde özgür olduklarını hissederler ama gerekli zamanlarda bundan belirli süreler için vazgeçebilirler. Özgürlük veya bağımsızlık ihtiya\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nMOW-k6sUgS9","colab_type":"text"},"source":["If you want to train on your own training data, run the next two cells. Otherwise skip them."]},{"cell_type":"code","metadata":{"id":"B7anKDCqMkrQ","colab_type":"code","outputId":"ae354750-3f66-464c-c456-b460a1b86fd8","executionInfo":{"status":"ok","timestamp":1570156321244,"user_tz":-180,"elapsed":14017,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73}},"source":["uploaded = files.upload()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-ef6c87d9-f8d6-474a-a62a-25a23cbb1713\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ef6c87d9-f8d6-474a-a62a-25a23cbb1713\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving ozgurlukword.docx to ozgurlukword.docx\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZtCtMN7FoZYo","colab_type":"code","outputId":"e78c9221-92fb-47f9-e905-331a64125630","executionInfo":{"status":"error","timestamp":1570156330982,"user_tz":-180,"elapsed":490,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["if uploaded:\n","  if type(uploaded) is not dict: uploaded = uploaded.files  ## Deal with filedit versions\n","  file_bytes = uploaded[uploaded.keys()[0]]\n","  utf8_string = file_bytes.decode(TEXT_ENCODING)\n","  file_contents = utf8_string if files else ''\n","  file_name = uploaded.keys()[0]\n","print(\"An excerpt: \\n\", file_contents[:664])"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-10-8804a0e1fce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m  \u001b[0;31m## Deal with filedit versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfile_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mutf8_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mfile_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutf8_string\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'TEXT_ENCODING' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"TO0NDmM0VgQU","colab_type":"text"},"source":["## Set up the recurrent LSTM network \n","\n","Before we can do anything, we have to define what our neural network looks like. This next cell creates a class which will contain the tensorflow graph and training parameters that make up the network."]},{"cell_type":"code","metadata":{"id":"UAK1D26NKGpJ","colab_type":"code","colab":{}},"source":["class RNN(object):\n","  \"\"\"Represents a Recurrent Neural Network using LSTM cells.\n","\n","  Attributes:\n","    num_layers: The integer number of hidden layers in the RNN.\n","    state_size: The size of the state in each LSTM cell.\n","    num_classes: Number of output classes. (E.g. 256 for Extended ASCII).\n","    batch_size: The number of training sequences to process per step.\n","    sequence_length: The number of chars in a training sequence.\n","    batch_index: Index within the dataset to start the next batch at.\n","    on_gpu_sequences: Generates the training inputs for a single batch.\n","    on_gpu_targets: Generates the training labels for a single batch.\n","    input_symbol: Placeholder for a single label for use during inference.\n","    temperature: Used when sampling outputs. A higher temperature will yield\n","      more variance; a lower one will produce the most likely outputs. Value\n","      should be between 0 and 1.\n","    initial_state: The LSTM State Tuple to initialize the network with. This\n","      will need to be set to the new_state computed by the network each cycle.\n","    logits: Unnormalized probability distribution for the next predicted\n","      label, for each timestep in each sequence.\n","    output_labels: A [batch_size, 1] int32 tensor containing a predicted\n","      label for each sequence in a batch. Only generated in infer mode.\n","  \"\"\"\n","  def __init__(self,\n","               rnn_num_layers=1,\n","               rnn_state_size=128,\n","               num_classes=256,\n","               rnn_batch_size=1,\n","               rnn_sequence_length=1):\n","    self.num_layers = rnn_num_layers\n","    self.state_size = rnn_state_size\n","    self.num_classes = num_classes\n","    self.batch_size = rnn_batch_size\n","    self.sequence_length = rnn_sequence_length\n","    self.batch_shape = (self.batch_size, self.sequence_length)\n","    print(\"Built LSTM: \",\n","          self.num_layers ,self.state_size ,self.num_classes ,\n","          self.batch_size ,self.sequence_length ,self.batch_shape)\n","\n","\n","  def build_training_model(self, dropout_rate, data_to_load):\n","    \"\"\"Sets up an RNN model for running a training job.\n","\n","    Args:\n","      dropout_rate: The rate at which weights may be forgotten during training.\n","      data_to_load: A numpy array of containing the training data, with each\n","        element in data_to_load being an integer representing a label. For\n","        example, for Extended ASCII, values may be 0 through 255.\n","\n","    Raises:\n","      ValueError: If mode is data_to_load is None.\n","    \"\"\"\n","    if data_to_load is None:\n","      raise ValueError('To continue, you must upload training data.')\n","    inputs = self._set_up_training_inputs(data_to_load)\n","    self._build_rnn(inputs, dropout_rate)\n","\n","  def build_inference_model(self):\n","    \"\"\"Sets up an RNN model for generating a sequence element by element.\n","    \"\"\"\n","    self.input_symbol = tf.placeholder(shape=[1, 1], dtype=tf.int32)\n","    self.temperature = tf.placeholder(shape=(), dtype=tf.float32,\n","                                      name='temperature')\n","    self.num_options = tf.placeholder(shape=(), dtype=tf.int32,\n","                                      name='num_options')\n","    self._build_rnn(self.input_symbol, 0.0)\n","\n","    self.temperature_modified_logits = tf.squeeze(\n","        self.logits, 0) / self.temperature\n","\n","    #for beam search\n","    self.normalized_probs = tf.nn.softmax(self.logits)\n","\n","    self.output_labels = tf.multinomial(self.temperature_modified_logits,\n","                                        self.num_options)\n","\n","  def _set_up_training_inputs(self, data):\n","    self.batch_index = tf.placeholder(shape=(), dtype=tf.int32)\n","    batch_input_length = self.batch_size * self.sequence_length\n","\n","    input_window = tf.slice(tf.constant(data, dtype=tf.int32),\n","                            [self.batch_index],\n","                            [batch_input_length + 1])\n","\n","    self.on_gpu_sequences = tf.reshape(\n","        tf.slice(input_window, [0], [batch_input_length]), self.batch_shape)\n","\n","    self.on_gpu_targets = tf.reshape(\n","        tf.slice(input_window, [1], [batch_input_length]), self.batch_shape)\n","\n","    return self.on_gpu_sequences\n","\n","  def _build_rnn(self, inputs, dropout_rate):\n","    \"\"\"Generates an RNN model using the passed functions.\n","\n","    Args:\n","      inputs: int32 Tensor with shape [batch_size, sequence_length] containing\n","        input labels.\n","      dropout_rate: A floating point value determining the chance that a weight\n","        is forgotten during evaluation.\n","    \"\"\"\n","    # Alias some commonly used functions\n","    dropout_wrapper = tf.contrib.rnn.DropoutWrapper\n","    lstm_cell = tf.contrib.rnn.LSTMCell\n","    multi_rnn_cell = tf.contrib.rnn.MultiRNNCell\n","\n","    self._cell = multi_rnn_cell(\n","        [dropout_wrapper(lstm_cell(self.state_size), 1.0, 1.0 - dropout_rate)\n","         for _ in range(self.num_layers)])\n","\n","    self.initial_state = self._cell.zero_state(self.batch_size, tf.float32)\n","\n","    embedding = tf.get_variable('embedding',\n","                                [self.num_classes, self.state_size])\n","\n","    embedding_input = tf.nn.embedding_lookup(embedding, inputs)\n","    output, self.new_state = tf.nn.dynamic_rnn(self._cell, embedding_input,\n","                                               initial_state=self.initial_state)\n","\n","    self.logits = tf.contrib.layers.fully_connected(output, self.num_classes,\n","                                                    activation_fn=None)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVEdNYclTSdv","colab_type":"text"},"source":["### Let's define our training parameters.\n","Feel free to leave these untouched at their default values and just run this cell as is. Later, you can come back here and experiment wth these. \n","These parameters are just for training. Further down at the inference step, we'll define parameters for the text-generation step."]},{"cell_type":"code","metadata":{"id":"qRPTh7_A2u80","colab_type":"code","cellView":"both","colab":{}},"source":["num_layers = 2\n","state_size = 256\n","batch_size = 64\n","sequence_length = 256\n","num_training_steps = 30000 # Takes about 40 minuets \n","steps_per_epoch = 500\n","learning_rate = 0.002\n","learning_rate_decay = 0.95\n","gradient_clipping = 5.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJ2NdzM5RHyK","colab_type":"text"},"source":["###Define your loss function\n","Loss is a measure of how well the neural network is modeling the data distribution. \n","\n","Pass in your logits and the targets you're training against. In this case, target_weights is a set of multipliers that will put higher emphasis on certain outputs. In this notebook, we'll give all outputs equal importance."]},{"cell_type":"code","metadata":{"id":"gbBZuBT6NhVG","colab_type":"code","colab":{}},"source":["def get_loss(logits, targets, target_weights):\n","  with tf.name_scope('loss'):\n","    return tf.contrib.seq2seq.sequence_loss(\n","        logits,\n","        targets,\n","        target_weights,\n","        average_across_timesteps=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Svir_HYvpHQn","colab_type":"text"},"source":["### Define your optimizer\n","This tells Tensorflow how to reduce the loss. We will use the popular [ADAM algorithm](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"]},{"cell_type":"code","metadata":{"id":"swLcZqsePGAG","colab_type":"code","colab":{}},"source":["def get_optimizer(loss, initial_learning_rate, gradient_clipping, global_step,\n","                  decay_steps, decay_rate):\n","\n","  with tf.name_scope('optimizer'):\n","    computed_learning_rate = tf.train.exponential_decay(\n","        initial_learning_rate,\n","        global_step,\n","        decay_steps,\n","        decay_rate,\n","        staircase=True)\n","\n","    optimizer = tf.train.AdamOptimizer(computed_learning_rate)\n","    trained_vars = tf.trainable_variables()\n","    gradients, _ = tf.clip_by_global_norm(\n","        tf.gradients(loss, trained_vars),\n","        gradient_clipping)\n","    training_op = optimizer.apply_gradients(\n","        zip(gradients, trained_vars),\n","        global_step=global_step)\n","\n","    return training_op, computed_learning_rate"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60O5Dw_Hr5-s","colab_type":"text"},"source":["### This class will let us view the progress of our training as it progresses."]},{"cell_type":"code","metadata":{"id":"lmfVg_eEeaOq","colab_type":"code","colab":{}},"source":["class LossPlotter(object):\n","  def __init__(self, history_length):\n","    self.global_steps = []\n","    self.losses = []\n","    self.averaged_loss_x = []\n","    self.averaged_loss_y = []\n","    self.history_length = history_length\n","\n","  def draw_plots(self):\n","    self._update_averages(self.global_steps, self.losses,\n","                          self.averaged_loss_x, self.averaged_loss_y)\n","\n","    plt.title('Average Loss Over Time')\n","    plt.xlabel('Global Step')\n","    plt.ylabel('Loss')\n","    plt.plot(self.averaged_loss_x, self.averaged_loss_y, label='Loss/Time (Avg)')\n","    plt.plot()\n","    plt.plot(self.global_steps, self.losses,\n","             label='Loss/Time (Last %d)' % self.history_length,\n","             alpha=.1, color='r')\n","    plt.plot()\n","    plt.legend()\n","    plt.show()\n","\n","    plt.title('Loss for the last 100 Steps')\n","    plt.xlabel('Global Step')\n","    plt.ylabel('Loss')\n","    plt.plot(self.global_steps, self.losses,\n","             label='Loss/Time (Last %d)' % self.history_length, color='r')\n","    plt.plot()\n","    plt.legend()\n","    plt.show()\n","\n","    # The notebook will be slowed down at the end of training if we plot the\n","    # entire history of raw data. Plot only the last 100 steps of raw data,\n","    # and the average of each 100 batches. Don't keep unused data.\n","    self.global_steps = []\n","    self.losses = []\n","    self.learning_rates = []\n","\n","  def log_step(self, global_step, loss):\n","    self.global_steps.append(global_step)\n","    self.losses.append(loss)\n","\n","  def _update_averages(self, x_list, y_list,\n","                       averaged_data_x, averaged_data_y):\n","    averaged_data_x.append(x_list[-1])\n","    averaged_data_y.append(sum(y_list) / self.history_length)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPwFDEiZhr6x","colab_type":"text"},"source":["## Now, we're going to start training our model.\n","\n","This could take a while, so you might want to grab a coffee. Every 30 seconds of training, we're going to save a checkpoint to make sure we don't lose our progress. To monitor the progress of your training, feel free to stop the training every once in a while and run the inference cell to generate text with your model!\n","\n","First, we will need to turn the plain text file into arrays of tokens (and, later,  back). To do this we will use this token mapper helper class:\n"]},{"cell_type":"code","metadata":{"id":"n98dKVTzkmpi","colab_type":"code","colab":{}},"source":["import string\n","class TokenMapper(object):\n","  def __init__(self):\n","    self.token_mapping = {}\n","    self.reverse_token_mapping = {}\n","  def buildFromData(self, utf8_string, limit=0.00004):\n","    print(\"Build token dictionary.\")\n","    total_num = len(utf8_string)\n","    sorted_tokens = sorted(Counter(utf8_string.decode('utf8')).items(), \n","                           key=lambda x: -x[1])\n","    # Filter tokens: Only allow printable characters (not control chars) and\n","    # limit to ones that are resonably common, i.e. skip strange esoteric \n","    # characters in order to reduce the dictionary size.\n","    filtered_tokens = filter(lambda t: t[0] in string.printable or \n","                             float(t[1])/total_num > limit, sorted_tokens)\n","    tokens, counts = zip(*filtered_tokens)\n","    self.token_mapping = dict(zip(tokens, range(len(tokens))))\n","    for c in string.printable:\n","      if c not in self.token_mapping:\n","        print(\"Skipped token for: \", c)\n","    self.reverse_token_mapping = {\n","        val: key for key, val in self.token_mapping.items()}\n","    print(\"Created dictionary: %d tokens\"%len(self.token_mapping))\n","  \n","  def mapchar(self, char):\n","    if char in self.token_mapping:\n","      return self.token_mapping[char]\n","    else:\n","      return self.token_mapping[' ']\n","  \n","  def mapstring(self, utf8_string):\n","    return [self.mapchar(c) for c in utf8_string]\n","  \n","  def maptoken(self, token):\n","    return self.reverse_token_mapping[token]\n","  \n","  def maptokens(self, int_array):\n","    return ''.join([self.reverse_token_mapping[c] for c in int_array])\n","  \n","  def size(self):\n","    return len(self.token_mapping)\n","  \n","  def alphabet(self):\n","    return ''.join([k for k,v in sorted(self.token_mapping.items(),key=itemgetter(1))])\n","\n","  def print(self):\n","    for k,v in sorted(self.token_mapping.items(),key=itemgetter(1)): print(k, v)\n","  \n","  def save(self, path):\n","    with open(path, 'wb') as json_file:\n","      json.dump(self.token_mapping, json_file)\n","  \n","  def restore(self, path):\n","    with open(path, 'r') as json_file:\n","      self.token_mapping = {}\n","      self.token_mapping.update(json.load(json_file))\n","      self.reverse_token_mapping = {val: key for key, val in self.token_mapping.items()}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XTGD7fxfEuK","colab_type":"text"},"source":["Now convert the raw input into a list of tokens."]},{"cell_type":"code","metadata":{"id":"6RiHe0bUo9eP","colab_type":"code","outputId":"a8505693-41a3-46ad-eeed-752ae547c7c1","executionInfo":{"status":"ok","timestamp":1570157486880,"user_tz":-180,"elapsed":3507,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":533}},"source":["# Clean the checkpoint directory and make a fresh one\n","!rm -rf {CHECKPOINT_DIR}\n","!mkdir {CHECKPOINT_DIR}\n","!ls -lt\n","\n","chars_in_batch = (sequence_length * batch_size)\n","file_len = len(file_contents)\n","unique_sequential_batches = file_len // chars_in_batch\n","\n","mapper = TokenMapper()\n","mapper.buildFromData(file_contents)\n","mapper.save(''.join([CHECKPOINT_DIR, 'token_mapping.json']))\n","\n","input_values = mapper.mapstring(file_contents)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["total 868\n","drwxr-xr-x 2 root root   4096 Oct  4 02:51  checkpoints\n","-rw-r--r-- 1 root root 182422 Oct  4 02:32  ozgurlukword.docx\n","-rw-r--r-- 1 root root 346854 Oct  4 02:30 'ozgurluk (1).txt'\n","-rw-r--r-- 1 root root 346854 Oct  4 02:27  ozgurluk.txt\n","drwxr-xr-x 1 root root   4096 Aug 27 16:17  sample_data\n","Build token dictionary.\n","Skipped token for:  q\n","Skipped token for:  Q\n","Skipped token for:  \"\n","Skipped token for:  $\n","Skipped token for:  %\n","Skipped token for:  &\n","Skipped token for:  +\n","Skipped token for:  <\n","Skipped token for:  =\n","Skipped token for:  >\n","Skipped token for:  [\n","Skipped token for:  \\\n","Skipped token for:  ]\n","Skipped token for:  ^\n","Skipped token for:  _\n","Skipped token for:  `\n","Skipped token for:  {\n","Skipped token for:  |\n","Skipped token for:  }\n","Skipped token for:  ~\n","Skipped token for:  \n","Skipped token for:  \u000b\n","Skipped token for:  \f\n","Created dictionary: 92 tokens\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V5He_ECNJc61","colab_type":"text"},"source":["###First, we'll build our neural network and add our training operations to the Tensorflow graph. \n","If you're continuing training after testing your generator, run the next three cells."]},{"cell_type":"code","metadata":{"id":"mgXvABhpJa1f","colab_type":"code","outputId":"3b010383-9b1e-44a8-cc77-b427846e9e63","executionInfo":{"status":"ok","timestamp":1570157516592,"user_tz":-180,"elapsed":2567,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":403}},"source":["tf.reset_default_graph()\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","print('Constructing model...')\n","\n","model = RNN(\n","    rnn_num_layers=num_layers,\n","    rnn_state_size=state_size,\n","    num_classes=mapper.size(),\n","    rnn_batch_size=batch_size,\n","    rnn_sequence_length=sequence_length)\n","\n","model.build_training_model(0.05, np.asarray(input_values))\n","print('Constructed model successfully.')\n","\n","print('Setting up training session...')\n","neutral_target_weights = tf.constant(\n","    np.ones(model.batch_shape),\n","    tf.float32\n",")\n","loss = get_loss(model.logits, model.on_gpu_targets, neutral_target_weights)\n","global_step = tf.get_variable('global_step', shape=(), trainable=False,\n","                              dtype=tf.int32)\n","training_step, computed_learning_rate = get_optimizer(\n","    loss,\n","    learning_rate,\n","    gradient_clipping,\n","    global_step,\n","    steps_per_epoch,\n","    learning_rate_decay\n",")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["W1004 02:51:54.893897 139710037956480 deprecation.py:323] From <ipython-input-20-12171759f484>:109: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","W1004 02:51:54.905046 139710037956480 deprecation.py:323] From <ipython-input-20-12171759f484>:109: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","W1004 02:51:54.943399 139710037956480 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W1004 02:51:54.959175 139710037956480 deprecation.py:323] From <ipython-input-20-12171759f484>:118: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["Constructing model...\n","Built LSTM:  2 256 92 64 256 (64, 256)\n"],"name":"stdout"},{"output_type":"stream","text":["W1004 02:51:55.331986 139710037956480 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["Constructed model successfully.\n","Setting up training session...\n"],"name":"stdout"},{"output_type":"stream","text":["W1004 02:51:56.878113 139710037956480 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/clip_ops.py:286: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"XNKzEmaRj5SF","colab_type":"text"},"source":["The supervisor will manage the training flow and checkpointing."]},{"cell_type":"code","metadata":{"id":"t90StbXJj4jt","colab_type":"code","outputId":"f466f7fc-4206-4806-a6ff-e889c642c8f9","executionInfo":{"status":"ok","timestamp":1570157531237,"user_tz":-180,"elapsed":489,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":103}},"source":["# Create a supervisor that will checkpoint the model in the CHECKPOINT_DIR\n","sv = tf.train.Supervisor(\n","    logdir=CHECKPOINT_DIR,\n","    global_step=global_step,\n","    save_model_secs=30)\n","print('Training session ready.')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["W1004 02:52:11.535816 139710037956480 deprecation.py:323] From <ipython-input-29-4ba04cba093f>:4: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.MonitoredTrainingSession\n"],"name":"stderr"},{"output_type":"stream","text":["Training session ready.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-tfXYyumK5z6","colab_type":"text"},"source":["###This next cell will begin the training cycle. \n","First, we will attempt to pick up training where we left off, if a previous checkpoint exists, then continue the training process."]},{"cell_type":"code","metadata":{"id":"1wfsDMuLLUr3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"6119cb82-9872-4222-8a90-3c99c74e2923","executionInfo":{"status":"ok","timestamp":1570171771053,"user_tz":-180,"elapsed":24,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}}},"source":["from datetime import datetime\n","start_time = datetime.now()\n","\n","with sv.managed_session(config=config) as sess:\n","  print('Training supervisor successfully initialized all variables.')\n","  if not file_len:\n","    raise ValueError('To continue, you must upload training data.')\n","  elif file_len < chars_in_batch:\n","    raise ValueError('To continue, you must upload a larger set of data.')\n","\n","  plotter = LossPlotter(100)\n","  step_number = sess.run(global_step)\n","  zero_state = sess.run([model.initial_state])\n","  max_batch_index = (unique_sequential_batches - 1) * chars_in_batch\n","  while not sv.should_stop() and step_number < num_training_steps:\n","    feed_dict = {\n","        model.batch_index: randint(0, max_batch_index),\n","        model.initial_state: zero_state\n","        }\n","    [_, _, training_loss, step_number, current_learning_rate, _] = sess.run(\n","        [model.on_gpu_sequences,\n","         model.on_gpu_targets,\n","         loss,\n","         global_step,\n","         computed_learning_rate,\n","         training_step],\n","        feed_dict)\n","    plotter.log_step(step_number, training_loss)\n","    if step_number % 100 == 0:\n","      clear_output(True)\n","      plotter.draw_plots()\n","      print('Latest checkpoint is: %s' %\n","            tf.train.latest_checkpoint(CHECKPOINT_DIR))\n","      print('Learning Rate is: %f' %\n","            current_learning_rate)\n","\n","    if step_number % 10 == 0:\n","      print('global step %d, loss=%f' % (step_number, training_loss))\n","\n","clear_output(True)\n","\n","print('Training completed in HH:MM:SS = ', datetime.now()-start_time)\n","print('Latest checkpoint is: %s' %\n","      tf.train.latest_checkpoint(CHECKPOINT_DIR))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Training completed in HH:MM:SS =  3:57:11.083234\n","Latest checkpoint is: ./checkpoints/model.ckpt-29987\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rpr5zK1UUlEd","colab_type":"text"},"source":["## Now, we're going to generate some text!\n","\n","Here, we'll use the **Beam Search** algorithm to generate some text with our trained model. Beam Search picks N possible next options from each of the current options at every step. This way, if the generator picks an item leading to a bad decision down the line, it can toss the bad result out and keep going with a more likely one."]},{"cell_type":"code","metadata":{"id":"sc8W1I0bJy-6","colab_type":"code","colab":{}},"source":["class BeamSearchCandidate(object):\n","  \"\"\"Represents a node within the search space during Beam Search.\n","\n","  Attributes:\n","    state: The resulting RNN state after the given sequence has been generated.\n","    sequence: The sequence of selections leading to this node.\n","    probability: The probability of the sequence occurring, computed as the sum\n","      of the probabilty of each character in the sequence at its respective\n","      step.\n","  \"\"\"\n","\n","  def __init__(self, init_state, sequence, probability):\n","    self.state = init_state\n","    self.sequence = sequence\n","    self.probability = probability\n","\n","  def search_from(self, tf_sess, rnn_model, temperature, num_options):\n","    \"\"\"Expands the num_options most likely next elements in the sequence.\n","\n","    Args:\n","      tf_sess: The Tensorflow session containing the rnn_model.\n","      rnn_model: The RNN to use to generate the next element in the sequence.\n","      temperature: Modifies the probabilities of each character, placing\n","        more emphasis on higher probabilities as the value approaches 0.\n","      num_options: How many potential next options to expand from this one.\n","\n","    Returns: A list of BeamSearchCandidate objects descended from this node.\n","    \"\"\"\n","    expanded_set = []\n","    feed = {rnn_model.input_symbol: np.array([[self.sequence[-1]]]),\n","            rnn_model.initial_state: self.state,\n","            rnn_model.temperature: temperature,\n","            rnn_model.num_options: num_options}\n","    [predictions, probabilities, new_state] = tf_sess.run(\n","        [rnn_model.output_labels,\n","         rnn_model.normalized_probs,\n","         rnn_model.new_state], feed)\n","    # Get the indices of the num_beams next picks\n","    picks = [predictions[0][x] for x in range(len(predictions[0]))]\n","    for new_char in picks:\n","      new_seq = deepcopy(self.sequence)\n","      new_seq.append(new_char)\n","      expanded_set.append(\n","          BeamSearchCandidate(new_state, new_seq,\n","                              probabilities[0][0][new_char] + self.probability))\n","    return expanded_set\n","\n","  def __eq__(self, other):\n","    return self.sequence == other.sequence\n","\n","  def __ne__(self, other):\n","    return not self.__eq__(other)\n","\n","  def __hash__(self):\n","    return hash(self.sequence())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97aGkvJGNFUH","colab_type":"code","colab":{}},"source":["def beam_search_generate_sequence(tf_sess, rnn_model, primer, temperature=0.85,\n","                                  termination_condition=None, num_beams=5):\n","  \"\"\"Implements a sequence generator using Beam Search.\n","\n","  Args:\n","    tf_sess: The Tensorflow session containing the rnn_model.\n","    rnn_model: The RNN to use to generate the next element in the sequence.\n","    temperature: Controls how 'Creative' the generated sequence is. Values\n","      close to 0 tend to generate the most likely sequence, while values\n","      closer to 1 generate more original sequences. Acceptable values are\n","      within (0, 1].\n","    termination_condition: A function taking one parameter, a list of\n","      integers, that returns True when a condition is met that signals to the\n","      RNN to return what it has generated so far.\n","    num_beams: The number of possible sequences to keep at each step of the\n","      generation process.\n","\n","  Returns: A list of at most num_beams BeamSearchCandidate objects.\n","  \"\"\"\n","  candidates = []\n","\n","  rnn_current_state = sess.run([rnn_model.initial_state])\n","  #Initialize the state for the primer\n","  for primer_val in primer[:-1]:\n","    feed = {rnn_model.input_symbol: np.array([[primer_val]]),\n","            rnn_model.initial_state: rnn_current_state\n","           }\n","    [rnn_current_state] = tf_sess.run([rnn_model.new_state], feed)\n","\n","  candidates.append(BeamSearchCandidate(rnn_current_state, primer, num_beams))\n","\n","  while True not in [termination_condition(x.sequence) for x in candidates]:\n","    new_candidates = []\n","    for candidate in candidates:\n","      expanded_candidates = candidate.search_from(\n","          tf_sess, rnn_model, temperature, num_beams)\n","      for new in expanded_candidates:\n","        if new not in new_candidates:\n","          #do not reevaluate duplicates\n","          new_candidates.append(new)\n","    candidates = sorted(new_candidates,\n","                        key=lambda x: x.probability, reverse=True)[:num_beams]\n","\n","  return [c for c in candidates if termination_condition(c.sequence)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qj0w_Vgs-oMJ","colab_type":"text"},"source":["Input something to start your generated text with, and set how characters long you want the text to be.\n","\"Creativity\" refers to how much emphasis your neural network puts on matching a pattern. If you notice looping in the output, try raising this value. If your output seems too random, try lowering it a bit.\n","If the results don't look too great in general, run the three training cells again for a bit longer. The lower your loss, the more closely your generated text will match the training data."]},{"cell_type":"code","metadata":{"id":"rAsyTCZvdFn5","colab_type":"code","outputId":"7f6ae8cf-6901-4d60-8547-731f841fe73c","executionInfo":{"status":"ok","timestamp":1570172105205,"user_tz":-180,"elapsed":489,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["tf.reset_default_graph()\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.InteractiveSession(config=config)\n","\n","model = RNN(\n","    rnn_num_layers=num_layers,\n","    rnn_state_size=state_size,\n","    num_classes=mapper.size(),\n","    rnn_batch_size=1,\n","    rnn_sequence_length=1)\n","\n","model.build_inference_model()\n","\n","sess.run(tf.global_variables_initializer())\n","saver = tf.train.Saver(tf.global_variables())\n","ckpt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n","saver.restore(sess, ckpt)\n","\n","def gen(start_with, pred, creativity):\n","  int_array = mapper.mapstring(start_with)\n","  candidates = beam_search_generate_sequence(\n","      sess, model, int_array, temperature=creativity,\n","      termination_condition=pred,\n","      num_beams=1)\n","  gentext = mapper.maptokens(candidates[0].sequence)\n","  return gentext\n","\n","def lengthlimit(n):\n","  return lambda text: len(text)>n\n","def sentences(n):\n","  return lambda text: mapper.maptokens(text).count(\".\")>=n\n","def paragraph():\n","  return lambda text: mapper.maptokens(text).count(\"\\n\")>0\n","\n"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Built LSTM:  2 256 92 1 1 (1, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["W1004 06:55:06.079364 139710037956480 deprecation.py:323] From <ipython-input-20-12171759f484>:75: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","W1004 06:55:06.112020 139710037956480 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"09ccehpqVKR8","colab_type":"code","cellView":"both","outputId":"62fa8a05-a350-4fe6-a222-cbf1bac3553f","executionInfo":{"status":"error","timestamp":1570198792224,"user_tz":-180,"elapsed":433,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["length_of_generated_text = 2000\n","creativity = 0.85  # Should be greater than 0 but less than 1\n","\n","print(gen(\"insan niye aldatır?\", lengthlimit(length_of_generated_text), creativity))"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-1-196f2680aba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcreativity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.85\u001b[0m  \u001b[0;31m# Should be greater than 0 but less than 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"insan niye aldatır?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengthlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_of_generated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreativity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"klTwA-RrFwR0","colab_type":"text"},"source":["## Let's save a copy of our trained RNN so we can do all kinds of cool things with it later."]},{"cell_type":"code","metadata":{"id":"hdxjJaayFuhS","colab_type":"code","outputId":"d50b912c-75a8-4008-9d50-66155a72bfd4","executionInfo":{"status":"error","timestamp":1570128625178,"user_tz":-180,"elapsed":2756752,"user":{"displayName":"Salih Tutun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC1xsF4UtdzPXZuep2xNgAzSzj_zB4j7mlxmw4ZQQ=s64","userId":"02520511273410275582"}},"colab":{"base_uri":"https://localhost:8080/","height":472}},"source":["save_model_to_drive = True  ## Set this to true to save directly to Google Drive.\n","\n","def save_model_hyperparameters(path):\n","  with open(path, 'w')  as json_file:\n","    model_params = {\n","        'num_layers': model.num_layers,\n","        'state_size': model.state_size,\n","        'num_classes': model.num_classes\n","    }\n","    json.dump(model_params, json_file)\n","\n","def save_to_drive(title, content):\n","  # Install the PyDrive wrapper & import libraries.\n","  !pip install -U -q PyDrive\n","  from pydrive.auth import GoogleAuth\n","  from pydrive.drive import GoogleDrive\n","  from google.colab import auth\n","  from oauth2client.client import GoogleCredentials\n","\n","  # Authenticate and create the PyDrive client.\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  drive = GoogleDrive(gauth)\n","\n","  newfile = drive.CreateFile({'title': title})\n","  newfile.SetContentFile(content)\n","  newfile.Upload()\n","  print('Uploaded file with ID %s as %s'% (newfile.get('id'),\n","         archive_name))\n","    \n","archive_name = ''.join([file_name,'_seedbank_char-rnn.zip'])\n","latest_model = tf.train.latest_checkpoint(CHECKPOINT_DIR).split('/')[2]\n","checkpoints_archive_path = ''.join(['./exports/',archive_name])\n","if not latest_model:\n","  raise ValueError('You must train a model before you can export one.')\n","  \n","%system mkdir exports\n","%rm -f {checkpoints_archive_path}\n","mapper.save(''.join([CHECKPOINT_DIR, 'token_mapping.json']))\n","save_model_hyperparameters(''.join([CHECKPOINT_DIR, 'model_attributes.json']))\n","%system zip '{checkpoints_archive_path}' -@ '{CHECKPOINT_DIR}checkpoint' \\\n","            '{CHECKPOINT_DIR}token_mapping.json' \\\n","            '{CHECKPOINT_DIR}model_attributes.json' \\\n","            '{CHECKPOINT_DIR}{latest_model}.'*\n","\n","if save_model_to_drive:\n","  save_to_drive(archive_name, checkpoints_archive_path)\n","else:\n","  files.download(checkpoints_archive_path)\n","\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\n","\n","zip error: Interrupted (aborting)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-24-a98b29d2829a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token_mapping.json'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0msave_model_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_attributes.json'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"system zip '{checkpoints_archive_path}' -@ '{CHECKPOINT_DIR}checkpoint'             '{CHECKPOINT_DIR}token_mapping.json'             '{CHECKPOINT_DIR}model_attributes.json'             '{CHECKPOINT_DIR}{latest_model}.'*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msave_model_to_drive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python2.7/dist-packages/decorator.pyc:decorator-gen-99>\u001b[0m in \u001b[0;36msx\u001b[0;34m(self, line, cell)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/osm.pyc\u001b[0m in \u001b[0;36msx\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# line magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_shell.pyc\u001b[0m in \u001b[0;36mgetoutput\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getoutput_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_show_pip_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pip_install_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_getoutput_compat\u001b[0;34m(shell, cmd, split, depth)\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m   result = _run_command(\n\u001b[0;32m--> 400\u001b[0;31m       shell.var_expand(cmd, depth=depth + 2), clear_streamed_output=True)\n\u001b[0m\u001b[1;32m    401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}